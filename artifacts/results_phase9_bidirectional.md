# Phase 9: Bidirectional Interop â€” OpenMP Workers Calling Haskell

## Goal

Demonstrate that OpenMP worker threads can call back into Haskell from
within a parallel region. This enables patterns like: OpenMP parallel for
where each iteration evaluates a Haskell function.

## Mechanism

1. Haskell creates a `FunPtr` via `foreign import ccall "wrapper"`
2. C code receives the `FunPtr` and calls it from within `#pragma omp parallel for`
3. The FunPtr wrapper stub (generated by GHC) automatically calls
   `rts_lock()` to acquire a Capability, evaluates the Haskell closure,
   then calls `rts_unlock()` to release it

Workers are pinned to Capabilities via `rts_setInCallCapability()`, so
`rts_lock()` returns their assigned Capability.

## Correctness Results

All tests pass at N1, N2, and N4:

| Test | Expected | Got | Status |
|------|----------|-----|--------|
| parallel_map sin(0) | 0.000000 | 0.000000 | OK |
| parallel_map sin(999*0.001) | 0.840930 | 0.840930 | OK |
| parallel_reduce (100K sin) | 1839.343386 | 1839.343386 | OK |
| polynomial reduce (10K) | 1109840.005000 | 1109840.005000 | OK |

The callback reduce matches the pure C OpenMP sinsum to full double precision.

## Performance Results (100K callbacks, i7-10750H)

| Threads | Pure C (ms) | Callback (ms) | Overhead | Per-callback |
|---------|-------------|---------------|----------|--------------|
| 1 | 1.69 | 46.60 | 27.6x | ~0.47 us |
| 2 | 1.17 | 60.43 | 51.8x | ~0.60 us |
| 4 | 0.71 | 57.91 | 82.1x | ~0.58 us |

## Analysis

1. **Per-callback cost is ~0.5 us**: This is the `rts_lock()/rts_unlock()`
   round-trip time, comparable to the fork/join overhead measured in Phase 3.
   Each callback acquires and releases a GHC Capability.

2. **Callback time doesn't scale with threads**: At N4, four workers compete
   for `rts_lock()` simultaneously. Since each callback holds a Capability
   briefly, contention limits parallel speedup for fine-grained callbacks.

3. **Ratio worsens with more threads**: The pure C sinsum scales linearly
   (1.69ms/1 -> 0.71ms/4), but callbacks don't, making the ratio look worse.
   The absolute callback time is fairly stable (~47-60ms).

4. **Practical for coarse-grained callbacks**: If each callback does
   milliseconds of work (not microseconds), the 0.5us `rts_lock` overhead
   is negligible. Example use cases:
   - OpenMP parallel for where each iteration calls a Haskell function
     that reads from a large data structure (HashMap, IntMap, etc.)
   - Parallel map where Haskell provides the transformation function
   - Hybrid pipelines: C does numerical work, calls Haskell for logic

## Conclusion

Bidirectional interop works correctly. OpenMP workers can call arbitrary
Haskell functions from within parallel regions. The mechanism is fully
automatic (GHC's FunPtr wrapper handles Capability management). The overhead
of ~0.5us per callback makes this practical for coarse-grained workloads
but not for tight inner loops where pure C should be used instead.
